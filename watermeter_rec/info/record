 
使用OpenCV进行仪表数值读取:

 解决方法有多种，
 比如，
 方案一：模板匹配+边缘检测+霍夫直线检测，
 方案二：神将网络（CNN）目标定位等， 其中CNN就有点麻烦了，需要一定数量的训练样本，太麻烦，
 方案三，模板匹配+k-means+直线拟合
 
 Cany边缘检测及 Hough变換检测得到最长直线
 












	目前指针仪表读数识别的研究主要方法包括：减影法 [4]、Hough直线变换法 [5]、指针区域特征法 [6]、基于轮廓拟合与径向分割的识别算法 [7] 等。
	工业上现有的基于Halcon的识别方法，主要通过把彩色图像转换成三个单通道图像，找到图像中的ROI (感兴趣区域)，增项ROI与背景的对比度来分割得到图像中的仪表盘，再进行极坐标变换 [8]。这种方法在背景简单，亮度变化小的场景下具有很高的识别效率，但是该方法在实际应用中，常常会因为光照，图像识别角度等原因，出现仪表盘分割的偏差，最终影响识别精度。
本文则从现有方法的基础上进行改进，使用模板匹配对表盘进行精准定位和仿射变换，减少极坐标变换带来的误差，对于同一种表，只需要创建一次模板。同时，再极坐标变换之后，利用形态学处理锁定定位指针和最值并进行几何运算。此外，模板匹配主要有基于灰度值的模板匹配，基于相关性的模板匹配和基于形状的模板匹配。本次算法中使用的是，基于形状的模板匹配，其适用于杂乱场景、尺寸缩放、光照变化等情况，能够处理复杂场景并且无需进行额外的模型训练过程，更有利于定位表盘。

 为了精准定位仪表盘，需要先创建仪表盘的模板，以便于识别是进行匹配：
将端正摆放的仪表图像上表盘中的圆心以及另外某一特征标志进行提取，
如表盘上的图形、汉字、字母等，目前最常用提取方法有两种,

第一种是对图像进行边缘检测后通过标志的几何形状来提取, 
另一种是通过彩色图像分割的方法 [9]，本文使用的方法是，大致截取图像中的标志，二值化分割出该标志，将其作为模板匹配的样本。
在识别中，先匹配定位到仪表盘，再进行仿射变换，将图像中的仪表旋转至水平裁剪出仪表，再进行极坐标变换。算法流程如图1。
2.1. 提取标志模板
模板创建包括圆心模板和标志模板，截取仪表中的标志，将图像转换成灰度值图像，并二值化分割提取出标志区域，如图2(a)，再利用create_shape_model()算子创建模板。并将模板识别文件保存，以便调用。使用write_shape_model()算子将两个模板识别文件进行保存。






















2.2. 模板匹配
创建完模板之后，开始采集新的图像，并用read_shape_model()读取之前保存的模板识别文件。模板匹配主要是通过判定测试图像与模板间的相似度，取相似性最大的样本为输入模式所属类别 [10]。其公式如下：
Cfg=100100∑Mi=1∑Nj=1∣∣fij∩​gij∣∣Tf+Tg
(1)
式中：f对应模板二值图像，g对应识别的仪表图像，二者的图像大小一致，均为M × N。 Tf
和 Tg 分别对应图像中值为1的像素个数。 ∩ 为与运算。

2.3. 仿射变换
首先读取标志模板得到其像素坐标(row1,col1)和旋转角度angel后，使用vector_angle_to_rigid()和affine_trans_image()将图像转正，仿射变换公式如下：
HomMat2D=[R00t1]=⎡⎣⎢100100t1⎤⎦⎥∗⎡⎣⎢R00001⎤⎦⎥=H(t)∗H(R)
(2)
⎛⎝⎜Row2Column21⎞⎠⎟=HomMat2D∗⎛⎝⎜Row1Column11⎞⎠⎟
(3)
式中：R为旋转矩阵；t为平移矩阵；(Row1, Column1)为原始点的像素坐标；(Row2, Column2)为仿射变换后的点的像素坐标。
过程如图3。再以转正后的图像为识别对象，读取圆心模板(row2, col2)，找到表盘圆心，得到其像素坐标。

分割仪表区域
得到了圆心和标志所在的行列坐标，若表盘半径为R，则R一定满足：

R=μ(row1−row2)
(4)
经过对多个仪表的测量拟合，我们将μ值定义为1.5。然后用reduce_domain()算子将表盘从图像中截取出来，如图4。





2.5. 传统识别方法
传统方法步骤为：
第一步，极坐标变换将圆形仪表转换为水平矩形区域 [11]。
第二步，刻度区域，获得最值区域的横坐标MaxCol和MinCol，形态学处理获得指针区域PointerCol。
第三步，利用Halcon训练好的OCR识别神经网络来识别最值Minvalue和MaxValue。

为了提高识别率，减少误差，可以自己使用Halcon训练分类器进行字符识别 。
本文采用基于BP (Back Propagation)神经网络的识别算法，将提取到的字符区域输入到一个三层神经网络OCR分类器中去 [14]。BP人工神经网络是一种多层前馈神经网络，由输入层、隐含层和输出层三部分组成，如图5 [15]。
第四步，几何计算。由于指针到最小刻度的距离与最值刻度值间的距离的比值等于读数和最小值的差与量程的比值所以，仪表读数为：
Scale=MinValue+(PointerCol−MinCol)∗(MaxValue−MinValue)MaxCol−MinCol
(5)
式中：Scale代表读数值；MinValue和MaxValue分别代表最小刻度值和最大刻度值；MinCol、MaxCol和PointerCol分别代表最小值区域的横坐标，最大值区域的横坐标和指针区域的横坐标。








				BP人工神经网络






	本文采用的样本种类为图6中的(a)、(b)、(c)三种仪表，每种仪表各1个。对其分别采用：(1) 用传统算法识别；(2) 手动截取表盘后将表盘旋转水平再用传统算法识别；(3) 基于模板匹配算法识别，也就是本文提出的算法。理论上，仪表定位越精确，识别进度越高，所以第(2)种算法识别的精度最高。分别将第(1)、(3)种和第(2)种进行对比。为了控制变量，三种方法均对相同的图像进行识别。
本文利用Halcon以及基于形状的模板匹配，相较于传统方法，可以看出以下优点：对于复杂混乱的场景可以进行更好的表盘定位；对于倾斜的仪表可以旋转至水平后识别；识别成功率和正确率更高。所以，本文提出的算法提高了表盘定位的精度进而提高了读数的精度。同时，算法识别一张图片所需时间仅为0.378 s，误差小于1%。实验结果也进一步证明了模板匹配定位表盘的算法可以对传统识别方法进行优化，提高生产效率，杜绝人工误读的情况，在需要监测仪表读数的领域中都可以广泛使用。

















仪表识别技术：识别出仪表的位置，得到仪表的类型和读数。
指针表，led数码表，字母，数字，小数位

蓝色框标注了仪表的位置，绿色文字标注了蓝色框内仪表的标签和数字。
机器学习中的检测+传统方法的颜色分割。流程如下：
       1）仪表检测

       2）数字区域分割

       3）数字检测
仪表检测


      目前开源的物体检测方法很多，对于上面场景来说，很多方法都可以达到理想的效果，比方说SSD，yolo，haar + adaboost等，传统方法，深度学习方法均可，建议采用多标签输出的方法，这样就可以一张图输入，多张标输出。

